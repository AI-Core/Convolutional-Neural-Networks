{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Datasets\n",
    "\n",
    "__Prerequisites__\n",
    "\n",
    "- [Convolutional Neural Networks](https://github.com/AI-Core/Convolutional-Neural-Networks)\n",
    "\n",
    "So far, we have only used the MNIST dataset, which is easily accessible through torchvision. What do we do when we have our own data which we want to use with PyTorch?\n",
    "\n",
    "To be compatible with a torch dataloader, we have to write a class from which we can create instances of the dataset. This class must overwrite the \\_\\_len\\_\\_ and \\_\\_getitem\\_\\_ functions. The \\_\\_len\\_\\_ function must return the length of the dataset we are loading in. The \\_\\_getitem\\_\\_ function must return an example datapoint given the index of it.\n",
    "\n",
    "In our \\_\\_init\\_\\_ function, we read in the variables which we can use to get items from our dataset. In this case, \n",
    "\n",
    "Today, we will implement a class which loads in the S40 detection dataset. Detection is when we want our algorithm to draw rectangles around the locations of specific objects within the image. As opposed to classification where we simply have a binary output indicating if the object is contained within the image.\n",
    "The dataset consists of an \"images\" folder which contains the input images and an \"annotations\" folder which, for each image, contains an xml file with the same name as the image and contains the co-ordinates for the top-left and bottom-right corners of the rectangular bounding box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "import xml.etree.ElementTree as ET\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "class S40dataset():\n",
    "\n",
    "    def __init__(self, img_dir='S40-data/images', annotation_dir='S40-data/annotations', transform=None):\n",
    "    \n",
    "    def __len__(self):\n",
    "        return data_size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return img, bndbox\n",
    "\n",
    "# Convert from  center co-ordinate, width and height format into corner co-ordinates format\n",
    "def unpack_bndbox(bndbox, img):\n",
    "    return bndbox\n",
    "\n",
    "#show the image with the bounding box rectangle drawn over it\n",
    "def show(batch, pred_bndbox=None):\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we build an algorithm to learn solutions to this problem? Find out in the CNN Detection notebook!\n",
    "\n",
    "__Next Steps__\n",
    "\n",
    "- [CNN Detection](https://github.com/AI-Core/Convolutional-Neural-Networks/blob/master/CNN%20Detection.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
